{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype-pendeteksi-objek.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjxiLGN3NDAd0W6uSBcCsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arifsoul/prototype-pendeteksi-objek/blob/master/prototype_pendeteksi_objek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVXKmFSHoFuL"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/judul.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2alXc7hJTsTR"
      },
      "source": [
        "#**PENGENALAN**\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/pengenalan.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsOdmvB-hts6"
      },
      "source": [
        "## 1. Python\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.python.org//tensorflow/models\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/python.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "Python adalah bahasa pemrograman interpretatif multiguna. Tidak seperti bahasa lain yang susah untuk dibaca dan dipahami, python lebih menekankan pada keterbacaan kode agar lebih mudah untuk memahami sintaks. Hal ini membuat Python sangat mudah dipelajari baik untuk pemula maupun untuk yang sudah menguasai bahasa pemrograman lain.\n",
        "\n",
        "Bahasa ini muncul pertama kali pada tahun 1991, dirancang oleh seorang bernama Guido van Rossum. Sampai saat ini Python masih dikembangkan oleh Python Software Foundation. Bahasa Python mendukung hampir semua sistem operasi, bahkan untuk sistem operasi Linux, hampir semua distronya sudah menyertakan Python di dalamnya.\n",
        "\n",
        "Dengan kode yang simpel dan mudah diimplementasikan, seorang programmer dapat lebih mengutamakan pengembangan aplikasi yang dibuat, bukan malah sibuk mencari syntax error.\n",
        "\n",
        "`print(\"Python sangat simpel\")`\n",
        "\n",
        "Hanya dengan menuliskan kode print seperti yang diatas, anda sudah bisa mencetak apapun yang anda inginkan di dalam tanda kurung `()`. Dibagian akhir kode pun, anda tidak harus mengakhirnya dengan tanda semicolon `;`\n",
        "\n",
        "sumber : [Belajarpython](https://belajarpython.com/tutorial/apa-itu-python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7w_8V0-Xv44"
      },
      "source": [
        "## 2. Google Colaboratory\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/colab.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "Google Colab adalah coding environment bahasa pemrograman Python dengan format “notebook” (mirip dengan [Jupyter notebook](https://jupyter.org/)), atau dengan kata lain ibaratnya Google meminjamkan kita komputer secara gratis untuk membuat program atau melakukan pengolahan data dari Google. Tidak seperti produk bawaan Google lainnya seperti Google Sheet, Google Drive, Google Docs dan lain-lain, google colab merupakan salah satu produk yang berbasis cloud. Meskipun demikian, Google Colab dapat kita gunakan secara gratis. Google colab dibuat khusus untuk programmer atau peneliti yang kesulitan untuk mendapatkan akses dengan spek tinggi.\n",
        "\n",
        "sumber : [DQLab](https://www.dqlab.id/belajar-python-dengan-google-colab#:~:text=Jika%20kalian%20perhatikan%2C%20Google%20Colab,melakukan%20pengolahan%20data%20dari%20Google.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNwdCnUWa6V4"
      },
      "source": [
        "## 3. Tensorflow Object Detection API\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/tensorflow.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "[*TensorFlow Object Detection API*](https://github.com/tensorflow/models/tree/master/research/object_detection) adalah *open source framework* yang dapat digunakan untuk mengembangkan, melatih, dan menggunakan model deteksi objek.  Sistem ini sudah banyak diterapkan pada berbagai produk Google antara lain pencarian gambar,  deteksi wajah dan plat nomor kendaraan pada *Google Streetview*, *Google Assistant*, *Waymo* atau *Self Driving Car*, dan lain-lain (“Tensorflow Object Detection *API*,” n.d.)\n",
        "\n",
        "*API* yang disediakan telah dilatih dengan dataset Common Object in Context (COCO)  yang terdiri 300.000 gambar berisi 90 jenis objek\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://humans-of.ai/editorial/categories.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "*API* ini juga menyediakan  berbagai model berbeda yang masing-masing mempunyai trade-off antara kecepatan dan akurasi dalam mendeteksi objek. Misalnya pada model SSD dengan menggunakan MobileNet dapat berjalan dengan komputasi ringan, sehingga dapat dijalankan secara real time di perangkat seluler (Liu et al., 2016). Sedangkan model Faster-RCNN  lebih berat secara komputasi, tetapi menghasilkan pendeteksian yang jauh lebih akurat (Huang et al., 2017).\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://i.imgur.com/D17bpFZ.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "Nilai *mAP (mean Average Precision)* menunjukkan tingkat akurasi deteksi objek dan letaknya. Nilai ini menjadi parameter utama untuk mengukur akurasi suatu model yang diaplikasikan dan seberapa bagus model tersebut untuk menangani objek tanpa ada kesalahan. Semakin tinggi nilai *mAP*, semakin tinggi pula akurasi yang didapat, namun sebagai konsekuensinya, kecepatan komputasi menjadi lebih rendah.\n",
        "\n",
        "\n",
        "**Tensorflow detection model terdiri dari:**\n",
        "1. Model deteksi yang bisa dilatih:\n",
        " * Single Shot Multibox Detector (SSD) with MobileNet \n",
        "(Howard et al., 2017),\n",
        " * SSD with Inception V2,\n",
        " * Region-Based Fully Convolutional Networks (R-FCN) with Resnet 101,\n",
        " * Faster RCNN with Resnet 101,\n",
        " * Faster RCNN with Inception Resnet v2\n",
        "2. Frozen weights (yang di-training dengan COCO dataset) untuk masing-masing model untuk digunakan dalam inference out-of-the-box.\n",
        "3. Jupyter notebook untuk melakukan inferensi out-of-the-box dengan suatu model.\n",
        "4. Local training scripts, distributed training, dan evaluation pipelines dengan Google Cloud.\n",
        "\n",
        "\n",
        "**Beberapa hal yang bisa dikembangkan lebih lanjut dari API ini adalah sebagai berikut:**\n",
        "1. Mencoba model overhead yang lebih akurat, tetapi beban komputasi lebih tinggi, lalu lihat berapa banyak perbedaan yang mereka buat.\n",
        "2. Mencari tahu cara mempercepat API, sehingga dapat digunakan untuk deteksi objek secara real-time pada perangkat seluler.\n",
        "3. Google juga menyediakan kemampuan untuk menggunakan model ini untuk melakukan transfer learning yaitu, memuat frozen models dan menambahkan lapisan output lain dengan kategori gambar yang berbeda.\n",
        "\n",
        "sumber :  [Syaikhoni, Ahmad & Aris Ariyadi. (2018). Deteksi Objek Dengan *Tensorflow Object Detection API*. Bandung. MTI Binus](https://mti.binus.ac.id/2018/12/26/deteksi-objek-dengan-tensorflow-object-detection-api/#:~:text=TensorFlow%20Object%20Detection%20API%20adalah,pada%20Google%20Streetview%2C%20Google%20Assistant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gERH_ZC60eGQ"
      },
      "source": [
        "## 3. *OpenCV*\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://opencv.org/\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/opencv.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "OpenCV adalah sebuah library (perpustakaan) yang digunakan untuk mengolah gambar dan video hingga kita mampu meng-ekstrak informasi didalamnya. OpenCV dapat berjalan di berbagai bahasa pemograman, seperti C, C++, Java, Python, dan juga support diberbagai platform seperti Windows, Linux, Mac OS, iOS dan Android."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YW9QRTgh-4N"
      },
      "source": [
        "## 4. Google Drive\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.google.com/intl/in/drive/about.html\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/gdrive.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "Google drive adalah layanan google untuk media penyimpanan data online (daring) berbasis cloud atau Internet yang pertama kali beredar pada tanggal 24 April 2012. Pada dasarnya layanan Google Drive sama seperti cloud storage lain semacam dropbox atau OneDrive.\n",
        "\n",
        "Aplikasi ini tersedia dalam bentuk dekstop ataupun smartphone. Pada beberapa jenis ponsel Google Drive atau GDrive menjadi aplikasi bawaan yang terinstal secara otomatis di sistem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0WJPtqiCRP"
      },
      "source": [
        "## 5. Github\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/github.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "GitHub adalah manajemen proyek dan sistem versioning code sekaligus platform jaringan sosial yang dirancang khusus bagi para developer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VduIHOZiFmB"
      },
      "source": [
        "## 6. MakeSense\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.makesense.ai/\"><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/makesense.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "MakeSense adalah alat online gratis untuk melabeli foto. Penggunaannya melalui browser sehingga tidak memerlukan instalasi yang rumit, cukup kunjungi situs webnya maka alat ini siap untuk digunakan. MakeSense dapat digunakan di berbagai sistem operasi komputer. Ini sempurna untuk proyek deeplearning visi komputer kecil, membuat proses menyiapkan kumpulan data jauh lebih mudah dan lebih cepat. Label yang telah disiapkan dapat diunduh dalam salah satu dari beberapa format yang didukung. Aplikasi ini ditulis dalam TypeScript dan didasarkan pada React / Redux duo.\n",
        "\n",
        "sumber : [SkalskiP](https://github.com/SkalskiP/make-sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0SLV-49sUIw"
      },
      "source": [
        "## 4. *Prototype* Pendeteksi Objek\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/proto.png?raw=true\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "*Prototype* Pendeteksi objek adalah model kerja dasar berupa kode program berisi langkah-langkah untuk memanfaatkan *Tensorflow Object Detection API*  untuk mendeteksi objek secara *real time* menggunakan *deep learning* dengan mengeksekusi tiap sesi program sesuai instruksi yang ada pada *Google Colaboratory*.\n",
        "\n",
        "*Prototype* Pendeteksi objek menggunakan [*Tensorflow Object Detection API*](https://github.com/tensorflow/models/tree/master/research/object_detection) dibuat pada *notebook Google Colaboratory* dengan memanfaatkan layanan pihak ketiga di luar Google seperti [Github](https://github.com/) untuk repositori dan [MakeSense](https://www.makesense.ai/) untuk pelabelan gambar.\n",
        "*Prototype* pendeteksi objek ini merupakan pengembangan dari berbagai kode program *open source* yang disusun secara sistematis berdasarkan langkah-langkah pelatihan pada *Tensorflow Object Detection API* serta dengan antarmuka yang dapat membantu pengguna untuk mengetahui berbagai instruksi yang ada.\n",
        "\n",
        "Prototype pendeteksi objek memiliki tiga tahap yang harus dilakukan, yaitu tahap persiapan, pelatihan *(training)* dan penyebaran *(deployment)*, setiap instruksi yang ada pada tahapan tersebut harus dijalankan secara berurutan dengan \"klik\" tombol *play* \n",
        "yang ada pada *notebook*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTrqxQreO81N"
      },
      "source": [
        "# **A. PERSIAPAN**\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/persiapan.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3tQQtlP4xRY"
      },
      "source": [
        "## 1. Instalasi *Prototype* \n",
        "\n",
        "> Penginstalan *prototype* dilakukan pada direktori *google drive* dengan menghubungkan akun *google*\n",
        "\n",
        "\n",
        "> Setelah Instalasi selesai akan muncul folder bernama \"prototype-pendeteksi-objek\" pada direktori /content/drive/MyDrive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08T1Pkt47tP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb794302-6945-4b53-a66a-4cc52ea51df2"
      },
      "source": [
        "#@title *Install Prototype*! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/arifsoul/prototype-pendeteksi-objek.git\n",
        "\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "Cloning into 'prototype-pendeteksi-objek'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 68 (delta 9), reused 66 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "Checking out files: 100% (39/39), done.\n",
            "/content/drive/MyDrive/prototype-pendeteksi-objek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A91qlpEAJB42",
        "cellView": "form"
      },
      "source": [
        "#@title *Uninstall Prototype*\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!rm -rf /content/drive/MyDrive/prototype-pendeteksi-objek\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZNmjowV9_H7"
      },
      "source": [
        "\n",
        "## 2. Pengumpulan *Dataset*\n",
        "\n",
        "Untuk Mengumpulkan *dataset* diperlukan gambar yang telah dilabeli berdasarkan objek yang ingin dideteksi\n",
        "\n",
        "\n",
        "> Tahap-tahap pengumpulan dataset:\n",
        "\n",
        "\n",
        "1. Mengumpulkan gambar objek yang ingin dideteksi dalam satu folder pada komputer\n",
        "2. Memberi nama folder gambar sesuai objek yang ingin dideteksi tanpa-menggunakan-spasi  \n",
        "3. Melabeli gambar dengan software [*MakeSense*](https://www.makesense.ai/) secara online\n",
        "4. Ekspor data label menjadi file .xml\n",
        "5. *Download* file .rar berisi file .xml dari software [*MakeSense*](https://www.makesense.ai/)\n",
        "6. Ekstrak file .rar ke dalam folder yang telah dibuat pada tahap 1\n",
        "7. Buat folder baru yang diberi nama sesuai sesuai objek yang ingin dideteksi tanpa menggunakan spasi pada direktori /prototype-pendeteksi-objek/dataset \n",
        "8. *Upload* folder dataset ke dalam  direktori /MyDrive/prototype-pendeteksi-objek/dataset dari akun *google drive*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMKM50ZYTCKL"
      },
      "source": [
        "#@title Pelabelan menggunakan *MakeSense* { vertical-output: true, display-mode: \"form\" }\n",
        "from IPython.display import Image\n",
        "Image(url='https://github.com/SkalskiP/make-sense/raw/develop/examples/demo-base.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0_hIhWQUEq5"
      },
      "source": [
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.makesense.ai/\"><img src=\"https://www.makesense.ai/make-sense-ico-transparent.png\"</a>\n",
        "\n",
        "**Mulai Pelabelan**\n",
        "\n",
        "\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAa75xtl4RZX"
      },
      "source": [
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"right\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq86mRCJ5yZl"
      },
      "source": [
        "#  **B. PELATIHAN *(TRAINING)***\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/training.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "> Proses pelatihan dilakukan untuk memperoleh file *Inference Graph* berformat \".pb\" yang akan digunakan untuk *deployment* pada sistem pendeteksi objek\n",
        "\n",
        "Tahapan yang perlu dilakukan antara lain:\n",
        "\n",
        "1. Persiapan file *TFrecord*\n",
        "2. Konfigurasi *training pipeline*\n",
        "3. *Transfer Learning* dan *Monitoring*\n",
        "4. Pengujian pendeteksi objek pada gambar menggunakan *checkpoint*\n",
        "5. *Export Inference Graph* yang telah di training berdasarkan *checkpoint*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mybLs1CF-PsL"
      },
      "source": [
        "## 1. Persiapan file TFrecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQp84kbm6Mw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e236a6c3-6d9e-4f5d-8e64-73cbdac1270e"
      },
      "source": [
        "#@title *Install Tensorflow Object Detection API* { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Versi_Tensorflow = \"2\" #@param [\"1\", \"2\"]\n",
        "version = Versi_Tensorflow +\".x\"\n",
        "%tensorflow_version $version\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install tf_slim \n",
        "!pip install lvis\n",
        "!pip install numpy\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        " \n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/:/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/slim'\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/prototype-pendeteksi-objek/models/'\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-lxml is already the newest version (4.2.1-1ubuntu0.4).\n",
            "python-pil is already the newest version (5.1.0-1ubuntu0.6).\n",
            "python-tk is already the newest version (2.7.17-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.23)\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.23)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "/content/drive/MyDrive/prototype-pendeteksi-objek/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL2SFmR_Qpn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bc62ba-8d19-4ecd-d065-680a1d20abde"
      },
      "source": [
        "#@title Ketik nama folder dataset yang telah dibuat atau pilih jenis pendeteksi dari dataset yang sudah disediakan!  { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "Pendeteksi = \"masker\" #@param [\"masker\", \"handphone\", \"bola\"] {allow-input: true}\n",
        "repo_url = 'https://github.com/arifsoul/' + Pendeteksi +'.git'\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/dataset\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek/dataset\n",
            "fatal: destination path 'masker' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/prototype-pendeteksi-objek/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YirlKxm4ZZxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bb3a5c-408c-40af-df48-3b33c98f309a"
      },
      "source": [
        "#@title *Convert* file .xml ke .csv! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek\n",
        "# Konversikan anotasi pada folder train yang berupa file xml ke dalam satu csv file,\n",
        "# Buat file `label_map.pbtxt` kepada folder `data/`.\n",
        "!python xml_to_csv.py -i dataset/$Pendeteksi -o annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi/dataset_labels.csv -l data_inference_graph/tensorflow_v$Versi_Tensorflow/$Pendeteksi/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek\n",
            "Successfully converted .xml to .csv\n",
            "Generate `data_inference_graph/tensorflow_v2/masker/label_map.pbtxt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tC4ldkYVC-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01cd55f-eab3-45ab-dbd9-68a95cfd0a7e"
      },
      "source": [
        "#@title *Split* data *train* dan *test*! { vertical-output: true, display-mode: \"form\" }\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "df = pd.read_csv('dataset_labels.csv')\n",
        "valid_frac = 0.2\n",
        "valid_size = int(valid_frac * df.filename.nunique())\n",
        "train_size = df.filename.nunique() - valid_size\n",
        "valid_df = df.loc[df.filename.isin(df.filename.sample(valid_size))]\n",
        "train_df = df.loc[df.filename.isin(valid_df.filename.unique())==False]\n",
        "\n",
        "train_df.to_csv('train_labels.csv', index_label=False, index=False)\n",
        "valid_df.to_csv('test_labels.csv', index_label=False, index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVxm9UZjLwLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc0dd18-3731-49c6-f258-c2b634d6b026"
      },
      "source": [
        "#@title Buat file TFrecord! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/\n",
        "\n",
        "# Buat file `train.record`\n",
        "!python generate_tfrecord-$Versi_Tensorflow-.py \\\n",
        "--csv_input annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi/train_labels.csv \\\n",
        "--output_path annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi/train.record \\\n",
        "--img_path dataset/$Pendeteksi/ \\\n",
        "--label_map data_inference_graph/tensorflow_v$Versi_Tensorflow/$Pendeteksi/label_map.pbtxt\n",
        "\n",
        "# Buat file `test.record`\n",
        "!python generate_tfrecord-$Versi_Tensorflow-.py \\\n",
        "--csv_input annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi/test_labels.csv \\\n",
        "--output_path annotations/tensorflow_v$Versi_Tensorflow/$Pendeteksi/test.record \\\n",
        "--img_path dataset/$Pendeteksi/ \\\n",
        "--label_map data_inference_graph/tensorflow_v$Versi_Tensorflow/$Pendeteksi/label_map.pbtxt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/train.record\n",
            "Successfully created the TFRecords: /content/drive/My Drive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPJEdz2yfUoG"
      },
      "source": [
        "## 2. Konfigurasi *training pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgQpEtylKwug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df64df59-086b-497d-863a-e3531d1ad7c2"
      },
      "source": [
        "#@title Pilih jenis *pre trained model* yang akan digunakan! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "model_dir='/content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2_coco_2018_03_29': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2_coco_2018_01_28': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_coco.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'ssd_inception_v2_coco_2018_01_28': {\n",
        "        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_inception_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "# Pilih model yang akan Anda gunakan \n",
        "# Pilih model di dalam `MODELS_CONFIG`.\n",
        "pre_trained_model = \"faster_rcnn_inception_v2_coco_2018_01_28\" #@param [\"ssd_mobilenet_v2_coco_2018_03_29\", \"faster_rcnn_inception_v2_coco_2018_01_28\", \"ssd_inception_v2_coco_2018_01_28\"]\n",
        "\n",
        "\n",
        "# Nama objek detection model yang digunakan.\n",
        "MODEL = MODELS_CONFIG[pre_trained_model]['model_name']\n",
        "\n",
        "# NAma file pipeline pada Tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[pre_trained_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fit di dalam Colab Tesla K80 GPU memory untuk model yang di pilih.\n",
        "batch_size = MODELS_CONFIG[pre_trained_model]['batch_size']\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek\n",
        "\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/models/research\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "#os.makedirs('pre_trained_model', exist_ok=True)\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/drive/MyDrive/prototype-pendeteksi-objek/pre_trained_model/tensorflow_v'+ Versi_Tensorflow + '/' + pre_trained_model\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint\n",
        "\n",
        "\n",
        "!cp /content/drive/MyDrive/prototype-pendeteksi-objek/label_map.pbtxt \\\n",
        "/content/drive/MyDrive/prototype-pendeteksi-objek/pre_trained_model/tensorflow_v$Versi_Tensorflow/$pre_trained_model\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek\n",
            "/content/drive/MyDrive/prototype-pendeteksi-objek/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFDClJlhoio"
      },
      "source": [
        "#@title Konfigurasi *pipeline* { vertical-output: true, display-mode: \"form\" }\n",
        "test_record_fname = '/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v'+Versi_Tensorflow+'/'+Pendeteksi+'/test.record'\n",
        "train_record_fname = '/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v'+Versi_Tensorflow+'/'+Pendeteksi+'/train.record'\n",
        "label_map_pbtxt_fname = '/content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi+'/label_map.pbtxt'\n",
        "\n",
        "# Jumlah training step.\n",
        "num_steps =  10000 #@param {type:\"integer\"}\n",
        "\n",
        "# Jumlah evaluation step.\n",
        "num_eval_steps =  50 \n",
        "\n",
        "# Jumlah sample di dalam folder \"test\".\n",
        "num_examples =  45 \n",
        "\n",
        "import os\n",
        "pipeline_fname = os.path.join('/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/samples/configs', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord file train dan test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set jumlah classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Set jumlah contoh (jumlah gambar).\n",
        "    s = re.sub('num_examples: [0-9]+',\n",
        "               'num_examples: {}'.format(num_examples), s)\n",
        "    \n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "#!cat {pipeline_fname}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLEaMzc-ShN"
      },
      "source": [
        "## 3. *Transfer Learning* dan *Monitoring*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWb4Yg0qWyOT"
      },
      "source": [
        "#@title Inisialisasi Tensorboard { vertical-output: true, display-mode: \"form\" }\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JphTUj5gXPRu"
      },
      "source": [
        "#@title *Monitoring* menggunakan *link* dibawah ini { vertical-output: true, display-mode: \"form\" }\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awwWCwarYEkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859afd29-a93e-44fc-b554-0a81a0c10f63"
      },
      "source": [
        "#@title Mulai *Training* { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "!pip install tensorflow-addons\n",
        "!python /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0603 11:42:59.564585 139837127919488 model_lib.py:812] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0603 11:42:59.564816 139837127919488 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0603 11:42:59.564912 139837127919488 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0603 11:42:59.564997 139837127919488 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0603 11:42:59.565078 139837127919488 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0603 11:42:59.565179 139837127919488 model_lib.py:828] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0603 11:42:59.565268 139837127919488 model_lib.py:865] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dde899850>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0603 11:42:59.565702 139837127919488 estimator.py:212] Using config: {'_model_dir': '/content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dde899850>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2dde895b90>) includes params argument, but params are not passed to Estimator.\n",
            "W0603 11:42:59.565912 139837127919488 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2dde895b90>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0603 11:42:59.566437 139837127919488 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0603 11:42:59.566602 139837127919488 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0603 11:42:59.566800 139837127919488 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0603 11:42:59.571571 139837127919488 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/train.record']\n",
            "I0603 11:42:59.596251 139837127919488 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/train.record']\n",
            "I0603 11:42:59.597742 139837127919488 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/tensorflow_v2/masker/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0603 11:42:59.597858 139837127919488 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0603 11:42:59.597933 139837127919488 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0603 11:42:59.602236 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0603 11:42:59.618842 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2dde8b5410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0603 11:42:59.650360 139837127919488 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2dde8b5410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f2dde030050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0603 11:42:59.814284 139837127919488 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f2dde030050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0603 11:42:59.815468 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0603 11:42:59.822089 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0603 11:42:59.946979 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0603 11:43:00.301480 139837127919488 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0603 11:43:00.331001 139837127919488 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:43:01.631343 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:43:01.753997 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 11:43:01.754351 139837127919488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0603 11:43:02.416444 139837127919488 deprecation.py:506] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0603 11:43:02.873265 139837127919488 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:43:02.875678 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:43:02.890402 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0603 11:43:03.159834 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0603 11:43:06.645591 139837127919488 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0603 11:43:06.646795 139837127919488 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0603 11:43:08.310978 139837127919488 monitored_session.py:240] Graph was finalized.\n",
            "2021-06-03 11:43:08.315662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-06-03 11:43:08.315863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c459d0c8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-03 11:43:08.315896: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-06-03 11:43:08.317704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-03 11:43:08.504728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.505299: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c459d0c540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-03 11:43:08.505333: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-06-03 11:43:08.505546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.505982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 11:43:08.506282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 11:43:08.507755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 11:43:08.509219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 11:43:08.509579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 11:43:08.511024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 11:43:08.511737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 11:43:08.514608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 11:43:08.514723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.515181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.515586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 11:43:08.515654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 11:43:08.516756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 11:43:08.516782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 11:43:08.516793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 11:43:08.516905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.517351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:43:08.517782: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-03 11:43:08.517825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0603 11:43:10.531263 139837127919488 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0603 11:43:10.685788 139837127919488 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "I0603 11:43:15.012694 139837127919488 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "2021-06-03 11:43:19.319929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 11:43:20.758945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 1.4093461, step = 0\n",
            "I0603 11:43:26.075312 139837127919488 basic_session_run_hooks.py:262] loss = 1.4093461, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.43675\n",
            "I0603 11:44:35.676260 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 1.43675\n",
            "INFO:tensorflow:loss = 2.8343954, step = 100 (69.602 sec)\n",
            "I0603 11:44:35.677318 139837127919488 basic_session_run_hooks.py:260] loss = 2.8343954, step = 100 (69.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.96146\n",
            "I0603 11:45:09.443233 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 2.96146\n",
            "INFO:tensorflow:loss = 0.8102257, step = 200 (33.767 sec)\n",
            "I0603 11:45:09.444762 139837127919488 basic_session_run_hooks.py:260] loss = 0.8102257, step = 200 (33.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.06015\n",
            "I0603 11:45:25.944487 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 6.06015\n",
            "INFO:tensorflow:loss = 1.4876926, step = 300 (16.501 sec)\n",
            "I0603 11:45:25.945487 139837127919488 basic_session_run_hooks.py:260] loss = 1.4876926, step = 300 (16.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.75695\n",
            "I0603 11:45:43.314830 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 5.75695\n",
            "INFO:tensorflow:loss = 1.4423081, step = 400 (17.370 sec)\n",
            "I0603 11:45:43.315860 139837127919488 basic_session_run_hooks.py:260] loss = 1.4423081, step = 400 (17.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.80479\n",
            "I0603 11:45:54.672259 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.80479\n",
            "INFO:tensorflow:loss = 1.5913998, step = 500 (11.358 sec)\n",
            "I0603 11:45:54.673394 139837127919488 basic_session_run_hooks.py:260] loss = 1.5913998, step = 500 (11.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.83153\n",
            "I0603 11:46:05.995317 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.83153\n",
            "INFO:tensorflow:loss = 0.5783844, step = 600 (11.323 sec)\n",
            "I0603 11:46:05.996355 139837127919488 basic_session_run_hooks.py:260] loss = 0.5783844, step = 600 (11.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76002\n",
            "I0603 11:46:17.410814 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76002\n",
            "INFO:tensorflow:loss = 0.42846268, step = 700 (11.415 sec)\n",
            "I0603 11:46:17.411752 139837127919488 basic_session_run_hooks.py:260] loss = 0.42846268, step = 700 (11.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.80433\n",
            "I0603 11:46:28.768863 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.80433\n",
            "INFO:tensorflow:loss = 1.3159336, step = 800 (11.358 sec)\n",
            "I0603 11:46:28.769730 139837127919488 basic_session_run_hooks.py:260] loss = 1.3159336, step = 800 (11.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.69949\n",
            "I0603 11:46:40.263847 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.69949\n",
            "INFO:tensorflow:loss = 0.6173557, step = 900 (11.495 sec)\n",
            "I0603 11:46:40.265233 139837127919488 basic_session_run_hooks.py:260] loss = 0.6173557, step = 900 (11.495 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.68163\n",
            "I0603 11:46:51.782380 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.68163\n",
            "INFO:tensorflow:loss = 0.7806898, step = 1000 (11.518 sec)\n",
            "I0603 11:46:51.783533 139837127919488 basic_session_run_hooks.py:260] loss = 0.7806898, step = 1000 (11.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76237\n",
            "I0603 11:47:03.194820 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76237\n",
            "INFO:tensorflow:loss = 0.7350019, step = 1100 (11.412 sec)\n",
            "I0603 11:47:03.195833 139837127919488 basic_session_run_hooks.py:260] loss = 0.7350019, step = 1100 (11.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71115\n",
            "I0603 11:47:14.674328 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71115\n",
            "INFO:tensorflow:loss = 0.5512476, step = 1200 (11.480 sec)\n",
            "I0603 11:47:14.676226 139837127919488 basic_session_run_hooks.py:260] loss = 0.5512476, step = 1200 (11.480 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73839\n",
            "I0603 11:47:26.118080 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73839\n",
            "INFO:tensorflow:loss = 2.15298, step = 1300 (11.443 sec)\n",
            "I0603 11:47:26.119155 139837127919488 basic_session_run_hooks.py:260] loss = 2.15298, step = 1300 (11.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.86106\n",
            "I0603 11:47:37.403416 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.86106\n",
            "INFO:tensorflow:loss = 1.4838526, step = 1400 (11.285 sec)\n",
            "I0603 11:47:37.404472 139837127919488 basic_session_run_hooks.py:260] loss = 1.4838526, step = 1400 (11.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.84248\n",
            "I0603 11:47:48.712473 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.84248\n",
            "INFO:tensorflow:loss = 1.6718012, step = 1500 (11.309 sec)\n",
            "I0603 11:47:48.713571 139837127919488 basic_session_run_hooks.py:260] loss = 1.6718012, step = 1500 (11.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.84188\n",
            "I0603 11:48:00.022272 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.84188\n",
            "INFO:tensorflow:loss = 0.7459718, step = 1600 (11.310 sec)\n",
            "I0603 11:48:00.023365 139837127919488 basic_session_run_hooks.py:260] loss = 0.7459718, step = 1600 (11.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.74019\n",
            "I0603 11:48:11.463665 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.74019\n",
            "INFO:tensorflow:loss = 0.34246165, step = 1700 (11.441 sec)\n",
            "I0603 11:48:11.464837 139837127919488 basic_session_run_hooks.py:260] loss = 0.34246165, step = 1700 (11.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7416\n",
            "I0603 11:48:22.903223 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7416\n",
            "INFO:tensorflow:loss = 0.42839915, step = 1800 (11.440 sec)\n",
            "I0603 11:48:22.904342 139837127919488 basic_session_run_hooks.py:260] loss = 0.42839915, step = 1800 (11.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76992\n",
            "I0603 11:48:34.305824 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76992\n",
            "INFO:tensorflow:loss = 0.72450846, step = 1900 (11.402 sec)\n",
            "I0603 11:48:34.306731 139837127919488 basic_session_run_hooks.py:260] loss = 0.72450846, step = 1900 (11.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.8096\n",
            "I0603 11:48:45.657082 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.8096\n",
            "INFO:tensorflow:loss = 0.29152915, step = 2000 (11.352 sec)\n",
            "I0603 11:48:45.658269 139837127919488 basic_session_run_hooks.py:260] loss = 0.29152915, step = 2000 (11.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.70966\n",
            "I0603 11:48:57.138613 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.70966\n",
            "INFO:tensorflow:loss = 0.17919149, step = 2100 (11.482 sec)\n",
            "I0603 11:48:57.139921 139837127919488 basic_session_run_hooks.py:260] loss = 0.17919149, step = 2100 (11.482 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.78454\n",
            "I0603 11:49:08.522236 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.78454\n",
            "INFO:tensorflow:loss = 1.2016823, step = 2200 (11.383 sec)\n",
            "I0603 11:49:08.523287 139837127919488 basic_session_run_hooks.py:260] loss = 1.2016823, step = 2200 (11.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.85869\n",
            "I0603 11:49:19.810624 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.85869\n",
            "INFO:tensorflow:loss = 0.6956413, step = 2300 (11.289 sec)\n",
            "I0603 11:49:19.812238 139837127919488 basic_session_run_hooks.py:260] loss = 0.6956413, step = 2300 (11.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.70899\n",
            "I0603 11:49:31.292972 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.70899\n",
            "INFO:tensorflow:loss = 0.8987466, step = 2400 (11.482 sec)\n",
            "I0603 11:49:31.293894 139837127919488 basic_session_run_hooks.py:260] loss = 0.8987466, step = 2400 (11.482 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76985\n",
            "I0603 11:49:42.695690 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76985\n",
            "INFO:tensorflow:loss = 0.77056354, step = 2500 (11.403 sec)\n",
            "I0603 11:49:42.696655 139837127919488 basic_session_run_hooks.py:260] loss = 0.77056354, step = 2500 (11.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71405\n",
            "I0603 11:49:54.171406 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71405\n",
            "INFO:tensorflow:loss = 2.098192, step = 2600 (11.476 sec)\n",
            "I0603 11:49:54.172544 139837127919488 basic_session_run_hooks.py:260] loss = 2.098192, step = 2600 (11.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.75135\n",
            "I0603 11:50:05.598206 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.75135\n",
            "INFO:tensorflow:loss = 1.6243595, step = 2700 (11.427 sec)\n",
            "I0603 11:50:05.599217 139837127919488 basic_session_run_hooks.py:260] loss = 1.6243595, step = 2700 (11.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7723\n",
            "I0603 11:50:16.997713 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7723\n",
            "INFO:tensorflow:loss = 0.22325264, step = 2800 (11.400 sec)\n",
            "I0603 11:50:16.998721 139837127919488 basic_session_run_hooks.py:260] loss = 0.22325264, step = 2800 (11.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.75722\n",
            "I0603 11:50:28.416881 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.75722\n",
            "INFO:tensorflow:loss = 1.017965, step = 2900 (11.419 sec)\n",
            "I0603 11:50:28.418035 139837127919488 basic_session_run_hooks.py:260] loss = 1.017965, step = 2900 (11.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.66833\n",
            "I0603 11:50:39.953122 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.66833\n",
            "INFO:tensorflow:loss = 1.3681511, step = 3000 (11.536 sec)\n",
            "I0603 11:50:39.954161 139837127919488 basic_session_run_hooks.py:260] loss = 1.3681511, step = 3000 (11.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.6458\n",
            "I0603 11:50:51.519414 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.6458\n",
            "INFO:tensorflow:loss = 1.5688108, step = 3100 (11.566 sec)\n",
            "I0603 11:50:51.520450 139837127919488 basic_session_run_hooks.py:260] loss = 1.5688108, step = 3100 (11.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73659\n",
            "I0603 11:51:02.965558 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73659\n",
            "INFO:tensorflow:loss = 1.6282415, step = 3200 (11.446 sec)\n",
            "I0603 11:51:02.966662 139837127919488 basic_session_run_hooks.py:260] loss = 1.6282415, step = 3200 (11.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76853\n",
            "I0603 11:51:14.369958 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76853\n",
            "INFO:tensorflow:loss = 0.5715486, step = 3300 (11.404 sec)\n",
            "I0603 11:51:14.370757 139837127919488 basic_session_run_hooks.py:260] loss = 0.5715486, step = 3300 (11.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71224\n",
            "I0603 11:51:25.848168 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71224\n",
            "INFO:tensorflow:loss = 0.6977661, step = 3400 (11.479 sec)\n",
            "I0603 11:51:25.849585 139837127919488 basic_session_run_hooks.py:260] loss = 0.6977661, step = 3400 (11.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.82425\n",
            "I0603 11:51:37.180513 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.82425\n",
            "INFO:tensorflow:loss = 0.2917843, step = 3500 (11.332 sec)\n",
            "I0603 11:51:37.181706 139837127919488 basic_session_run_hooks.py:260] loss = 0.2917843, step = 3500 (11.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.65123\n",
            "I0603 11:51:48.739560 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.65123\n",
            "INFO:tensorflow:loss = 0.28917953, step = 3600 (11.559 sec)\n",
            "I0603 11:51:48.740658 139837127919488 basic_session_run_hooks.py:260] loss = 0.28917953, step = 3600 (11.559 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.78108\n",
            "I0603 11:52:00.127643 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.78108\n",
            "INFO:tensorflow:loss = 0.38224208, step = 3700 (11.388 sec)\n",
            "I0603 11:52:00.128674 139837127919488 basic_session_run_hooks.py:260] loss = 0.38224208, step = 3700 (11.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.83576\n",
            "I0603 11:52:11.445275 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.83576\n",
            "INFO:tensorflow:loss = 0.6885381, step = 3800 (11.318 sec)\n",
            "I0603 11:52:11.446360 139837127919488 basic_session_run_hooks.py:260] loss = 0.6885381, step = 3800 (11.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.83427\n",
            "I0603 11:52:22.764862 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.83427\n",
            "INFO:tensorflow:loss = 1.2415891, step = 3900 (11.320 sec)\n",
            "I0603 11:52:22.765938 139837127919488 basic_session_run_hooks.py:260] loss = 1.2415891, step = 3900 (11.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.70478\n",
            "I0603 11:52:34.252786 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.70478\n",
            "INFO:tensorflow:loss = 0.63695693, step = 4000 (11.488 sec)\n",
            "I0603 11:52:34.253919 139837127919488 basic_session_run_hooks.py:260] loss = 0.63695693, step = 4000 (11.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.76225\n",
            "I0603 11:52:45.665380 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.76225\n",
            "INFO:tensorflow:loss = 0.53551525, step = 4100 (11.413 sec)\n",
            "I0603 11:52:45.666448 139837127919488 basic_session_run_hooks.py:260] loss = 0.53551525, step = 4100 (11.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.74316\n",
            "I0603 11:52:57.102889 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.74316\n",
            "INFO:tensorflow:loss = 0.7225214, step = 4200 (11.437 sec)\n",
            "I0603 11:52:57.103774 139837127919488 basic_session_run_hooks.py:260] loss = 0.7225214, step = 4200 (11.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71986\n",
            "I0603 11:53:08.570957 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71986\n",
            "INFO:tensorflow:loss = 0.47806203, step = 4300 (11.468 sec)\n",
            "I0603 11:53:08.571905 139837127919488 basic_session_run_hooks.py:260] loss = 0.47806203, step = 4300 (11.468 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4372 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "I0603 11:53:16.702739 139837127919488 basic_session_run_hooks.py:606] Saving checkpoints for 4372 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 11:53:17.732894 139837127919488 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 11:53:17.734279 139837127919488 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0603 11:53:17.734417 139837127919488 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2dd00bb090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0603 11:53:17.778894 139837127919488 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2dd00bb090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2dd00c20e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0603 11:53:17.952049 139837127919488 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2dd00c20e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0603 11:53:18.470550 139837127919488 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:53:19.705618 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:53:19.828722 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 11:53:19.829095 139837127919488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:53:20.739055 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 11:53:20.754401 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0603 11:53:21.144044 139837127919488 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0603 11:53:21.829446 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0603 11:53:22.010202 139837127919488 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0603 11:53:22.526560 139837127919488 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-03T11:53:22Z\n",
            "I0603 11:53:22.541815 139837127919488 evaluation.py:255] Starting evaluation at 2021-06-03T11:53:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0603 11:53:22.967514 139837127919488 monitored_session.py:240] Graph was finalized.\n",
            "2021-06-03 11:53:22.968660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:53:22.968948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 11:53:22.969066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 11:53:22.969096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 11:53:22.969121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 11:53:22.969146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 11:53:22.969175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 11:53:22.969196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 11:53:22.969219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 11:53:22.969302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:53:22.969631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:53:22.969854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 11:53:22.969897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 11:53:22.969911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 11:53:22.969921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 11:53:22.970025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:53:22.970292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 11:53:22.970537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-4372\n",
            "I0603 11:53:22.972470 139837127919488 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-4372\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0603 11:53:23.955320 139837127919488 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0603 11:53:24.095547 139837127919488 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 25 images.\n",
            "I0603 11:53:29.458306 139833234319104 coco_evaluation.py:293] Performing evaluation on 25 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0603 11:53:29.458778 139833234319104 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0603 11:53:29.461934 139833234319104 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-03-11:53:30\n",
            "I0603 11:53:30.220650 139837127919488 evaluation.py:275] Finished evaluation at 2021-06-03-11:53:30\n",
            "INFO:tensorflow:Saving dict for global step 4372: DetectionBoxes_Precision/mAP = 0.2705641, DetectionBoxes_Precision/mAP (large) = 0.31302375, DetectionBoxes_Precision/mAP (medium) = 0.08747066, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.52785254, DetectionBoxes_Precision/mAP@.75IOU = 0.19194786, DetectionBoxes_Recall/AR@1 = 0.32426107, DetectionBoxes_Recall/AR@10 = 0.41083744, DetectionBoxes_Recall/AR@100 = 0.4780788, DetectionBoxes_Recall/AR@100 (large) = 0.57149124, DetectionBoxes_Recall/AR@100 (medium) = 0.12, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17986381, Loss/BoxClassifierLoss/localization_loss = 0.21046728, Loss/RPNLoss/localization_loss = 0.52337426, Loss/RPNLoss/objectness_loss = 0.42276067, Loss/total_loss = 1.3364661, global_step = 4372, learning_rate = 0.0002, loss = 1.3364661\n",
            "I0603 11:53:30.220930 139837127919488 estimator.py:2049] Saving dict for global step 4372: DetectionBoxes_Precision/mAP = 0.2705641, DetectionBoxes_Precision/mAP (large) = 0.31302375, DetectionBoxes_Precision/mAP (medium) = 0.08747066, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.52785254, DetectionBoxes_Precision/mAP@.75IOU = 0.19194786, DetectionBoxes_Recall/AR@1 = 0.32426107, DetectionBoxes_Recall/AR@10 = 0.41083744, DetectionBoxes_Recall/AR@100 = 0.4780788, DetectionBoxes_Recall/AR@100 (large) = 0.57149124, DetectionBoxes_Recall/AR@100 (medium) = 0.12, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17986381, Loss/BoxClassifierLoss/localization_loss = 0.21046728, Loss/RPNLoss/localization_loss = 0.52337426, Loss/RPNLoss/objectness_loss = 0.42276067, Loss/total_loss = 1.3364661, global_step = 4372, learning_rate = 0.0002, loss = 1.3364661\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4372: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-4372\n",
            "I0603 11:53:31.031120 139837127919488 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4372: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-4372\n",
            "INFO:tensorflow:global_step/sec: 3.86316\n",
            "I0603 11:53:34.456528 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 3.86316\n",
            "INFO:tensorflow:loss = 0.22901681, step = 4400 (25.886 sec)\n",
            "I0603 11:53:34.458137 139837127919488 basic_session_run_hooks.py:260] loss = 0.22901681, step = 4400 (25.886 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71681\n",
            "I0603 11:53:45.928607 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71681\n",
            "INFO:tensorflow:loss = 0.933625, step = 4500 (11.471 sec)\n",
            "I0603 11:53:45.929635 139837127919488 basic_session_run_hooks.py:260] loss = 0.933625, step = 4500 (11.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.74\n",
            "I0603 11:53:57.370232 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.74\n",
            "INFO:tensorflow:loss = 0.4130818, step = 4600 (11.442 sec)\n",
            "I0603 11:53:57.371381 139837127919488 basic_session_run_hooks.py:260] loss = 0.4130818, step = 4600 (11.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.6993\n",
            "I0603 11:54:08.865401 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.6993\n",
            "INFO:tensorflow:loss = 0.5060042, step = 4700 (11.495 sec)\n",
            "I0603 11:54:08.866318 139837127919488 basic_session_run_hooks.py:260] loss = 0.5060042, step = 4700 (11.495 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.77617\n",
            "I0603 11:54:20.259896 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.77617\n",
            "INFO:tensorflow:loss = 0.65940416, step = 4800 (11.395 sec)\n",
            "I0603 11:54:20.260976 139837127919488 basic_session_run_hooks.py:260] loss = 0.65940416, step = 4800 (11.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.65533\n",
            "I0603 11:54:31.813460 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.65533\n",
            "INFO:tensorflow:loss = 0.3337086, step = 4900 (11.554 sec)\n",
            "I0603 11:54:31.814567 139837127919488 basic_session_run_hooks.py:260] loss = 0.3337086, step = 4900 (11.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.85087\n",
            "I0603 11:54:43.111778 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.85087\n",
            "INFO:tensorflow:loss = 0.1097357, step = 5000 (11.298 sec)\n",
            "I0603 11:54:43.112673 139837127919488 basic_session_run_hooks.py:260] loss = 0.1097357, step = 5000 (11.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.85206\n",
            "I0603 11:54:54.408610 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.85206\n",
            "INFO:tensorflow:loss = 0.50195765, step = 5100 (11.297 sec)\n",
            "I0603 11:54:54.409577 139837127919488 basic_session_run_hooks.py:260] loss = 0.50195765, step = 5100 (11.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.78196\n",
            "I0603 11:55:05.795604 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.78196\n",
            "INFO:tensorflow:loss = 0.66305083, step = 5200 (11.398 sec)\n",
            "I0603 11:55:05.807313 139837127919488 basic_session_run_hooks.py:260] loss = 0.66305083, step = 5200 (11.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.81944\n",
            "I0603 11:55:17.134144 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.81944\n",
            "INFO:tensorflow:loss = 0.52899164, step = 5300 (11.328 sec)\n",
            "I0603 11:55:17.135028 139837127919488 basic_session_run_hooks.py:260] loss = 0.52899164, step = 5300 (11.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.74658\n",
            "I0603 11:55:28.567206 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.74658\n",
            "INFO:tensorflow:loss = 0.17284499, step = 5400 (11.433 sec)\n",
            "I0603 11:55:28.568307 139837127919488 basic_session_run_hooks.py:260] loss = 0.17284499, step = 5400 (11.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.71587\n",
            "I0603 11:55:40.040553 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.71587\n",
            "INFO:tensorflow:loss = 0.40393013, step = 5500 (11.474 sec)\n",
            "I0603 11:55:40.042317 139837127919488 basic_session_run_hooks.py:260] loss = 0.40393013, step = 5500 (11.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.78666\n",
            "I0603 11:55:51.421415 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.78666\n",
            "INFO:tensorflow:loss = 0.9957695, step = 5600 (11.380 sec)\n",
            "I0603 11:55:51.422288 139837127919488 basic_session_run_hooks.py:260] loss = 0.9957695, step = 5600 (11.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.65996\n",
            "I0603 11:56:02.968821 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.65996\n",
            "INFO:tensorflow:loss = 0.24864118, step = 5700 (11.548 sec)\n",
            "I0603 11:56:02.969919 139837127919488 basic_session_run_hooks.py:260] loss = 0.24864118, step = 5700 (11.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7316\n",
            "I0603 11:56:14.421483 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7316\n",
            "INFO:tensorflow:loss = 1.0903964, step = 5800 (11.453 sec)\n",
            "I0603 11:56:14.422652 139837127919488 basic_session_run_hooks.py:260] loss = 1.0903964, step = 5800 (11.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.68662\n",
            "I0603 11:56:25.933436 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.68662\n",
            "INFO:tensorflow:loss = 0.23620768, step = 5900 (11.512 sec)\n",
            "I0603 11:56:25.934303 139837127919488 basic_session_run_hooks.py:260] loss = 0.23620768, step = 5900 (11.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.74166\n",
            "I0603 11:56:37.372903 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.74166\n",
            "INFO:tensorflow:loss = 0.6147576, step = 6000 (11.440 sec)\n",
            "I0603 11:56:37.373921 139837127919488 basic_session_run_hooks.py:260] loss = 0.6147576, step = 6000 (11.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7963\n",
            "I0603 11:56:48.741308 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7963\n",
            "INFO:tensorflow:loss = 1.3684971, step = 6100 (11.368 sec)\n",
            "I0603 11:56:48.742278 139837127919488 basic_session_run_hooks.py:260] loss = 1.3684971, step = 6100 (11.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.75245\n",
            "I0603 11:57:00.166708 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.75245\n",
            "INFO:tensorflow:loss = 1.0748477, step = 6200 (11.426 sec)\n",
            "I0603 11:57:00.167851 139837127919488 basic_session_run_hooks.py:260] loss = 1.0748477, step = 6200 (11.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.77333\n",
            "I0603 11:57:11.564866 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.77333\n",
            "INFO:tensorflow:loss = 0.42688364, step = 6300 (11.398 sec)\n",
            "I0603 11:57:11.565921 139837127919488 basic_session_run_hooks.py:260] loss = 0.42688364, step = 6300 (11.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.6581\n",
            "I0603 11:57:23.114751 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.6581\n",
            "INFO:tensorflow:loss = 0.48054364, step = 6400 (11.550 sec)\n",
            "I0603 11:57:23.115768 139837127919488 basic_session_run_hooks.py:260] loss = 0.48054364, step = 6400 (11.550 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.81945\n",
            "I0603 11:57:34.453333 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.81945\n",
            "INFO:tensorflow:loss = 1.3335818, step = 6500 (11.339 sec)\n",
            "I0603 11:57:34.454346 139837127919488 basic_session_run_hooks.py:260] loss = 1.3335818, step = 6500 (11.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.64046\n",
            "I0603 11:57:46.026798 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.64046\n",
            "INFO:tensorflow:loss = 1.3624755, step = 6600 (11.575 sec)\n",
            "I0603 11:57:46.028890 139837127919488 basic_session_run_hooks.py:260] loss = 1.3624755, step = 6600 (11.575 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73665\n",
            "I0603 11:57:57.472831 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73665\n",
            "INFO:tensorflow:loss = 0.3950999, step = 6700 (11.445 sec)\n",
            "I0603 11:57:57.473820 139837127919488 basic_session_run_hooks.py:260] loss = 0.3950999, step = 6700 (11.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.60355\n",
            "I0603 11:58:09.095961 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.60355\n",
            "INFO:tensorflow:loss = 1.3609432, step = 6800 (11.623 sec)\n",
            "I0603 11:58:09.097136 139837127919488 basic_session_run_hooks.py:260] loss = 1.3609432, step = 6800 (11.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.77633\n",
            "I0603 11:58:20.490246 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.77633\n",
            "INFO:tensorflow:loss = 1.3081474, step = 6900 (11.394 sec)\n",
            "I0603 11:58:20.491165 139837127919488 basic_session_run_hooks.py:260] loss = 1.3081474, step = 6900 (11.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.69636\n",
            "I0603 11:58:31.989289 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.69636\n",
            "INFO:tensorflow:loss = 1.4261892, step = 7000 (11.499 sec)\n",
            "I0603 11:58:31.990227 139837127919488 basic_session_run_hooks.py:260] loss = 1.4261892, step = 7000 (11.499 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7569\n",
            "I0603 11:58:43.408843 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7569\n",
            "INFO:tensorflow:loss = 0.2983773, step = 7100 (11.420 sec)\n",
            "I0603 11:58:43.409739 139837127919488 basic_session_run_hooks.py:260] loss = 0.2983773, step = 7100 (11.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7477\n",
            "I0603 11:58:54.840460 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7477\n",
            "INFO:tensorflow:loss = 0.6720449, step = 7200 (11.432 sec)\n",
            "I0603 11:58:54.841462 139837127919488 basic_session_run_hooks.py:260] loss = 0.6720449, step = 7200 (11.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.62143\n",
            "I0603 11:59:06.439444 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.62143\n",
            "INFO:tensorflow:loss = 1.5720482, step = 7300 (11.599 sec)\n",
            "I0603 11:59:06.440338 139837127919488 basic_session_run_hooks.py:260] loss = 1.5720482, step = 7300 (11.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73455\n",
            "I0603 11:59:17.888231 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73455\n",
            "INFO:tensorflow:loss = 0.06264645, step = 7400 (11.449 sec)\n",
            "I0603 11:59:17.889057 139837127919488 basic_session_run_hooks.py:260] loss = 0.06264645, step = 7400 (11.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73559\n",
            "I0603 11:59:29.335656 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73559\n",
            "INFO:tensorflow:loss = 0.29346114, step = 7500 (11.447 sec)\n",
            "I0603 11:59:29.336500 139837127919488 basic_session_run_hooks.py:260] loss = 0.29346114, step = 7500 (11.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.75408\n",
            "I0603 11:59:40.758905 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.75408\n",
            "INFO:tensorflow:loss = 1.6195532, step = 7600 (11.424 sec)\n",
            "I0603 11:59:40.760642 139837127919488 basic_session_run_hooks.py:260] loss = 1.6195532, step = 7600 (11.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.78589\n",
            "I0603 11:59:52.140810 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.78589\n",
            "INFO:tensorflow:loss = 0.3961122, step = 7700 (11.382 sec)\n",
            "I0603 11:59:52.142194 139837127919488 basic_session_run_hooks.py:260] loss = 0.3961122, step = 7700 (11.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.79531\n",
            "I0603 12:00:03.510586 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.79531\n",
            "INFO:tensorflow:loss = 0.18286127, step = 7800 (11.369 sec)\n",
            "I0603 12:00:03.511652 139837127919488 basic_session_run_hooks.py:260] loss = 0.18286127, step = 7800 (11.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7975\n",
            "I0603 12:00:14.877367 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7975\n",
            "INFO:tensorflow:loss = 0.5243927, step = 7900 (11.367 sec)\n",
            "I0603 12:00:14.878370 139837127919488 basic_session_run_hooks.py:260] loss = 0.5243927, step = 7900 (11.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73145\n",
            "I0603 12:00:26.330208 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73145\n",
            "INFO:tensorflow:loss = 0.4853739, step = 8000 (11.453 sec)\n",
            "I0603 12:00:26.331184 139837127919488 basic_session_run_hooks.py:260] loss = 0.4853739, step = 8000 (11.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.6304\n",
            "I0603 12:00:37.917215 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.6304\n",
            "INFO:tensorflow:loss = 0.20341133, step = 8100 (11.587 sec)\n",
            "I0603 12:00:37.918344 139837127919488 basic_session_run_hooks.py:260] loss = 0.20341133, step = 8100 (11.587 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.69675\n",
            "I0603 12:00:49.415711 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.69675\n",
            "INFO:tensorflow:loss = 0.4914556, step = 8200 (11.498 sec)\n",
            "I0603 12:00:49.416691 139837127919488 basic_session_run_hooks.py:260] loss = 0.4914556, step = 8200 (11.498 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.73259\n",
            "I0603 12:01:00.867074 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.73259\n",
            "INFO:tensorflow:loss = 0.47789228, step = 8300 (11.451 sec)\n",
            "I0603 12:01:00.868105 139837127919488 basic_session_run_hooks.py:260] loss = 0.47789228, step = 8300 (11.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.91945\n",
            "I0603 12:01:12.078541 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.91945\n",
            "INFO:tensorflow:loss = 0.3225968, step = 8400 (11.212 sec)\n",
            "I0603 12:01:12.079677 139837127919488 basic_session_run_hooks.py:260] loss = 0.3225968, step = 8400 (11.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.67638\n",
            "I0603 12:01:23.604073 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.67638\n",
            "INFO:tensorflow:loss = 0.35606828, step = 8500 (11.526 sec)\n",
            "I0603 12:01:23.605195 139837127919488 basic_session_run_hooks.py:260] loss = 0.35606828, step = 8500 (11.526 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.80134\n",
            "I0603 12:01:34.966022 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.80134\n",
            "INFO:tensorflow:loss = 0.3290162, step = 8600 (11.362 sec)\n",
            "I0603 12:01:34.967332 139837127919488 basic_session_run_hooks.py:260] loss = 0.3290162, step = 8600 (11.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.83647\n",
            "I0603 12:01:46.282734 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.83647\n",
            "INFO:tensorflow:loss = 1.1484144, step = 8700 (11.317 sec)\n",
            "I0603 12:01:46.283941 139837127919488 basic_session_run_hooks.py:260] loss = 1.1484144, step = 8700 (11.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.84329\n",
            "I0603 12:01:57.590734 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.84329\n",
            "INFO:tensorflow:loss = 0.289516, step = 8800 (11.308 sec)\n",
            "I0603 12:01:57.592072 139837127919488 basic_session_run_hooks.py:260] loss = 0.289516, step = 8800 (11.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.85874\n",
            "I0603 12:02:08.879022 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.85874\n",
            "INFO:tensorflow:loss = 0.43633735, step = 8900 (11.288 sec)\n",
            "I0603 12:02:08.880002 139837127919488 basic_session_run_hooks.py:260] loss = 0.43633735, step = 8900 (11.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.80864\n",
            "I0603 12:02:20.231522 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.80864\n",
            "INFO:tensorflow:loss = 0.4535339, step = 9000 (11.353 sec)\n",
            "I0603 12:02:20.232585 139837127919488 basic_session_run_hooks.py:260] loss = 0.4535339, step = 9000 (11.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.72194\n",
            "I0603 12:02:31.696842 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.72194\n",
            "INFO:tensorflow:loss = 1.6484181, step = 9100 (11.465 sec)\n",
            "I0603 12:02:31.697892 139837127919488 basic_session_run_hooks.py:260] loss = 1.6484181, step = 9100 (11.465 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.81417\n",
            "I0603 12:02:43.042207 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.81417\n",
            "INFO:tensorflow:loss = 0.054781258, step = 9200 (11.345 sec)\n",
            "I0603 12:02:43.043149 139837127919488 basic_session_run_hooks.py:260] loss = 0.054781258, step = 9200 (11.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.68365\n",
            "I0603 12:02:54.558096 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.68365\n",
            "INFO:tensorflow:loss = 1.4801365, step = 9300 (11.516 sec)\n",
            "I0603 12:02:54.559077 139837127919488 basic_session_run_hooks.py:260] loss = 1.4801365, step = 9300 (11.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.84673\n",
            "I0603 12:03:05.861714 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.84673\n",
            "INFO:tensorflow:loss = 0.20722988, step = 9400 (11.304 sec)\n",
            "I0603 12:03:05.862799 139837127919488 basic_session_run_hooks.py:260] loss = 0.20722988, step = 9400 (11.304 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9497 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "I0603 12:03:16.752605 139837127919488 basic_session_run_hooks.py:606] Saving checkpoints for 9497 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 12:03:17.738065 139837127919488 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 12:03:17.739398 139837127919488 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0603 12:03:17.739567 139837127919488 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2d4ef7b5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0603 12:03:17.779147 139837127919488 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2d4ef7b5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2d4e58c8c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0603 12:03:17.941793 139837127919488 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2d4e58c8c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0603 12:03:18.478771 139837127919488 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:03:19.715714 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:03:19.842833 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 12:03:19.843172 139837127919488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:03:20.976215 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:03:20.990965 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0603 12:03:22.675779 139837127919488 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-03T12:03:22Z\n",
            "I0603 12:03:22.691633 139837127919488 evaluation.py:255] Starting evaluation at 2021-06-03T12:03:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0603 12:03:23.119415 139837127919488 monitored_session.py:240] Graph was finalized.\n",
            "2021-06-03 12:03:23.120211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:03:23.120556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:03:23.120682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:03:23.120712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:03:23.120737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:03:23.120761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:03:23.120784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:03:23.120806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:03:23.120829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:03:23.120931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:03:23.121224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:03:23.121459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:03:23.121501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:03:23.121516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:03:23.121526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:03:23.121640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:03:23.121926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:03:23.122158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-9497\n",
            "I0603 12:03:23.124254 139837127919488 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-9497\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0603 12:03:24.106362 139837127919488 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0603 12:03:24.239219 139837127919488 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 25 images.\n",
            "I0603 12:03:28.511986 139834416420608 coco_evaluation.py:293] Performing evaluation on 25 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0603 12:03:28.512379 139834416420608 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0603 12:03:28.514795 139834416420608 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.466\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-03-12:03:29\n",
            "I0603 12:03:29.279194 139837127919488 evaluation.py:275] Finished evaluation at 2021-06-03-12:03:29\n",
            "INFO:tensorflow:Saving dict for global step 9497: DetectionBoxes_Precision/mAP = 0.43213448, DetectionBoxes_Precision/mAP (large) = 0.49902222, DetectionBoxes_Precision/mAP (medium) = 0.14535087, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6990986, DetectionBoxes_Precision/mAP@.75IOU = 0.46556652, DetectionBoxes_Recall/AR@1 = 0.41157636, DetectionBoxes_Recall/AR@10 = 0.52192116, DetectionBoxes_Recall/AR@100 = 0.58066505, DetectionBoxes_Recall/AR@100 (large) = 0.66798246, DetectionBoxes_Recall/AR@100 (medium) = 0.2, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16728285, Loss/BoxClassifierLoss/localization_loss = 0.1529391, Loss/RPNLoss/localization_loss = 0.7391661, Loss/RPNLoss/objectness_loss = 0.37304303, Loss/total_loss = 1.4324313, global_step = 9497, learning_rate = 0.0002, loss = 1.4324313\n",
            "I0603 12:03:29.279478 139837127919488 estimator.py:2049] Saving dict for global step 9497: DetectionBoxes_Precision/mAP = 0.43213448, DetectionBoxes_Precision/mAP (large) = 0.49902222, DetectionBoxes_Precision/mAP (medium) = 0.14535087, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6990986, DetectionBoxes_Precision/mAP@.75IOU = 0.46556652, DetectionBoxes_Recall/AR@1 = 0.41157636, DetectionBoxes_Recall/AR@10 = 0.52192116, DetectionBoxes_Recall/AR@100 = 0.58066505, DetectionBoxes_Recall/AR@100 (large) = 0.66798246, DetectionBoxes_Recall/AR@100 (medium) = 0.2, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16728285, Loss/BoxClassifierLoss/localization_loss = 0.1529391, Loss/RPNLoss/localization_loss = 0.7391661, Loss/RPNLoss/objectness_loss = 0.37304303, Loss/total_loss = 1.4324313, global_step = 9497, learning_rate = 0.0002, loss = 1.4324313\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9497: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-9497\n",
            "I0603 12:03:29.285390 139837127919488 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9497: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-9497\n",
            "INFO:tensorflow:global_step/sec: 4.18647\n",
            "I0603 12:03:29.748213 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 4.18647\n",
            "INFO:tensorflow:loss = 0.21837272, step = 9500 (23.886 sec)\n",
            "I0603 12:03:29.749140 139837127919488 basic_session_run_hooks.py:260] loss = 0.21837272, step = 9500 (23.886 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.7971\n",
            "I0603 12:03:41.115817 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.7971\n",
            "INFO:tensorflow:loss = 0.8538077, step = 9600 (11.368 sec)\n",
            "I0603 12:03:41.116660 139837127919488 basic_session_run_hooks.py:260] loss = 0.8538077, step = 9600 (11.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.79826\n",
            "I0603 12:03:52.481500 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.79826\n",
            "INFO:tensorflow:loss = 0.46640736, step = 9700 (11.366 sec)\n",
            "I0603 12:03:52.482517 139837127919488 basic_session_run_hooks.py:260] loss = 0.46640736, step = 9700 (11.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.67247\n",
            "I0603 12:04:04.012229 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.67247\n",
            "INFO:tensorflow:loss = 0.3789734, step = 9800 (11.531 sec)\n",
            "I0603 12:04:04.013923 139837127919488 basic_session_run_hooks.py:260] loss = 0.3789734, step = 9800 (11.531 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.75659\n",
            "I0603 12:04:15.432187 139837127919488 basic_session_run_hooks.py:692] global_step/sec: 8.75659\n",
            "INFO:tensorflow:loss = 0.10460726, step = 9900 (11.419 sec)\n",
            "I0603 12:04:15.433329 139837127919488 basic_session_run_hooks.py:260] loss = 0.10460726, step = 9900 (11.419 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "I0603 12:04:26.571914 139837127919488 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0603 12:04:27.968757 139837127919488 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 12:04:27.993041 139837127919488 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "I0603 12:04:27.994356 139837127919488 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/prototype-pendeteksi-objek/annotations/masker/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0603 12:04:27.994508 139837127919488 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2db410b910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0603 12:04:28.034644 139837127919488 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f2db410b910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2db4f55cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0603 12:04:28.205195 139837127919488 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f2db4f55cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0603 12:04:28.716026 139837127919488 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:29.942204 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:30.071537 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 12:04:30.071931 139837127919488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:31.228672 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:31.243241 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0603 12:04:32.823382 139837127919488 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-03T12:04:32Z\n",
            "I0603 12:04:32.838961 139837127919488 evaluation.py:255] Starting evaluation at 2021-06-03T12:04:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0603 12:04:33.256837 139837127919488 monitored_session.py:240] Graph was finalized.\n",
            "2021-06-03 12:04:33.257536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:33.257845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:04:33.257954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:04:33.257982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:04:33.258006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:04:33.258030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:04:33.258057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:04:33.258078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:04:33.258099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:04:33.258190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:33.258493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:33.258702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:04:33.258743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:04:33.258760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:04:33.258772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:04:33.258872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:33.259142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:33.259361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "I0603 12:04:33.261471 139837127919488 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0603 12:04:34.321024 139837127919488 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0603 12:04:34.454706 139837127919488 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 25 images.\n",
            "I0603 12:04:38.786839 139834416420608 coco_evaluation.py:293] Performing evaluation on 25 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0603 12:04:38.788120 139834416420608 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0603 12:04:38.790353 139834416420608 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-03-12:04:39\n",
            "I0603 12:04:39.550234 139837127919488 evaluation.py:275] Finished evaluation at 2021-06-03-12:04:39\n",
            "INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.39418286, DetectionBoxes_Precision/mAP (large) = 0.45047945, DetectionBoxes_Precision/mAP (medium) = 0.16437042, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6825033, DetectionBoxes_Precision/mAP@.75IOU = 0.4434868, DetectionBoxes_Recall/AR@1 = 0.37906405, DetectionBoxes_Recall/AR@10 = 0.5187192, DetectionBoxes_Recall/AR@100 = 0.5705665, DetectionBoxes_Recall/AR@100 (large) = 0.65745616, DetectionBoxes_Recall/AR@100 (medium) = 0.22, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1590666, Loss/BoxClassifierLoss/localization_loss = 0.15185961, Loss/RPNLoss/localization_loss = 0.7320868, Loss/RPNLoss/objectness_loss = 0.40305358, Loss/total_loss = 1.4460666, global_step = 10000, learning_rate = 0.0002, loss = 1.4460666\n",
            "I0603 12:04:39.550528 139837127919488 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.39418286, DetectionBoxes_Precision/mAP (large) = 0.45047945, DetectionBoxes_Precision/mAP (medium) = 0.16437042, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6825033, DetectionBoxes_Precision/mAP@.75IOU = 0.4434868, DetectionBoxes_Recall/AR@1 = 0.37906405, DetectionBoxes_Recall/AR@10 = 0.5187192, DetectionBoxes_Recall/AR@100 = 0.5705665, DetectionBoxes_Recall/AR@100 (large) = 0.65745616, DetectionBoxes_Recall/AR@100 (medium) = 0.22, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1590666, Loss/BoxClassifierLoss/localization_loss = 0.15185961, Loss/RPNLoss/localization_loss = 0.7320868, Loss/RPNLoss/objectness_loss = 0.40305358, Loss/total_loss = 1.4460666, global_step = 10000, learning_rate = 0.0002, loss = 1.4460666\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "I0603 12:04:39.556493 139837127919488 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0603 12:04:39.557419 139837127919488 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0603 12:04:39.834793 139837127919488 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:41.042520 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:41.168483 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 12:04:41.168825 139837127919488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:42.302743 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:04:42.317391 139837127919488 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0603 12:04:42.996230 139837127919488 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0603 12:04:42.996503 139837127919488 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0603 12:04:42.997069 139837127919488 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0603 12:04:42.997181 139837127919488 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0603 12:04:42.997260 139837127919488 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0603 12:04:42.997330 139837127919488 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0603 12:04:42.997395 139837127919488 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-06-03 12:04:42.997918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:42.998293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:04:42.998405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:04:42.998475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:04:42.998501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:04:42.998525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:04:42.998547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:04:42.998568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:04:42.998589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:04:42.998686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:42.998981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:42.999187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:04:42.999226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:04:42.999241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:04:42.999251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:04:42.999352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:42.999647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:04:42.999868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "I0603 12:04:43.003216 139837127919488 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0603 12:04:43.563838 139837127919488 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0603 12:04:43.564050 139837127919488 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/export/Servo/temp-b'1622721879'/saved_model.pb\n",
            "I0603 12:04:44.468837 139837127919488 builder_impl.py:425] SavedModel written to: /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/export/Servo/temp-b'1622721879'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.21778095.\n",
            "I0603 12:04:44.673456 139837127919488 estimator.py:371] Loss for final step: 0.21778095.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6o0DSk0W7nq"
      },
      "source": [
        "## 4. Pembuatan *Inference Graph* dari data training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVmRi2PskMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063905af-c0c3-434a-c85a-f464b9d0f7bf"
      },
      "source": [
        "#@title Buat folder untuk menyimpan *inference graph!* { vertical-output: true, display-mode: \"form\" }\n",
        "inference_graph_dir = '/content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --output_directory  {inference_graph_dir} \\\n",
        "    --trained_checkpoint_prefix {last_model_path}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0603 12:17:05.136089 140682822809472 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:17:06.289468 140682822809472 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:17:06.413699 140682822809472 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0603 12:17:06.414054 140682822809472 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0603 12:17:06.468289 140682822809472 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0603 12:17:06.992416 140682822809472 deprecation.py:506] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0603 12:17:07.468466 140682822809472 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:17:07.473361 140682822809472 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0603 12:17:07.491324 140682822809472 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0603 12:17:08.128775 140682822809472 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0603 12:17:08.220114 140682822809472 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0603 12:17:08.223178 140682822809472 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0603 12:17:08.224087 140682822809472 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "209 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.85m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/11.28k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/8.20k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (8, 8/8 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x8, 8.19k/8.19k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/3.08k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (3, 3/3 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x3, 3.07k/3.07k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "209 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.17k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-06-03 12:17:10.208047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-03 12:17:10.214270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.214735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:17:10.215126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:17:10.217206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:17:10.219373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:17:10.220024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:17:10.222369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:17:10.225857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:17:10.318793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:17:10.318913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.319390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.319802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:17:10.324720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-06-03 12:17:10.324900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557feae7bd40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-03 12:17:10.324927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-06-03 12:17:10.496363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.496971: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557ff4c86540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-03 12:17:10.496999: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-06-03 12:17:10.497166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.497613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:17:10.497680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:17:10.497705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:17:10.497727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:17:10.497746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:17:10.497766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:17:10.497784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:17:10.497803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:17:10.497872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.498311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.498727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:17:10.498825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:17:10.499894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:17:10.499919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:17:10.499936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:17:10.500082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.500563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:10.500971: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-03 12:17:10.501012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "I0603 12:17:10.504128 140682822809472 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0603 12:17:12.124613 140682822809472 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-06-03 12:17:12.615667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:12.616139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:17:12.616217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:17:12.616240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:17:12.616262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:17:12.616287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:17:12.616309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:17:12.616328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:17:12.616348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:17:12.616441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:12.616894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:12.617275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:17:12.617315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:17:12.617328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:17:12.617338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:17:12.617440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:12.617882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:12.618277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "I0603 12:17:12.619976 140682822809472 saver.py:1284] Restoring parameters from /content/drive/MyDrive/prototype-pendeteksi-objek/data_training/tensorflow_v2/masker/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0603 12:17:13.292552 140682822809472 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0603 12:17:13.292809 140682822809472 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0603 12:17:13.656165 140682822809472 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0603 12:17:13.758828 140682822809472 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "2021-06-03 12:17:14.081051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:14.081778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-03 12:17:14.081995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-03 12:17:14.082120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-03 12:17:14.082156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-03 12:17:14.082179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-03 12:17:14.082202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-03 12:17:14.082228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-03 12:17:14.082259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-03 12:17:14.082385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:14.083231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:14.083938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-03 12:17:14.084006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-03 12:17:14.084043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-03 12:17:14.084059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-03 12:17:14.084236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:14.085016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-03 12:17:14.085661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9552 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0603 12:17:14.661016 140682822809472 deprecation.py:323] From /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0603 12:17:14.661728 140682822809472 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0603 12:17:14.661890 140682822809472 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v2/masker/saved_model/saved_model.pb\n",
            "I0603 12:17:15.073983 140682822809472 builder_impl.py:425] SavedModel written to: /content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v2/masker/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v2/masker/pipeline.config\n",
            "I0603 12:17:15.110565 140682822809472 config_util.py:254] Writing pipeline config file to /content/drive/MyDrive/prototype-pendeteksi-objek/data_inference_graph/tensorflow_v2/masker/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO2rfQ2_-Uoe"
      },
      "source": [
        "# **C. PENYEBARAN *(DEPLOYMENT)***\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a><img src=\"https://github.com/arifsoul/prototype-pendeteksi-objek/blob/master/resources/deployment.png?raw=true\"</a>\n",
        "\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "> File *inference graph* yang telah diperoleh pada tahap *training* akan dibaca pada program sistem pendeteksi objek untuk mengenali pola gambar yang telah ditentukan\n",
        "\n",
        ">Berikut merupakan *prototype* sistem pendeteksi objek yang dapat bekerja secara *realtime* menggunakan webcam\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbaKfbOxQCwi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc1ee667-7914-4b0b-f6a9-3c58f50483e3"
      },
      "source": [
        "#@title Object Detector { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "Versi_Tensorflow = \"2\" #@param [\"1\", \"2\"]\n",
        "version = Versi_Tensorflow +\".x\"\n",
        "%tensorflow_version $version\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install tf_slim \n",
        "!pip install lvis\n",
        "!pip install numpy\n",
        "%cd /content/drive/MyDrive/prototype-pendeteksi-objek/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        " \n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/:/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/slim'\n",
        "\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "Pendeteksi = \"masker\" #@param [\"ssd_mobilenet_v2_coco_2018_03_29\", \"faster_rcnn_inception_v2_coco_2018_01_28\", \"ssd_inception_v2_coco_2018_01_28\"] {allow-input: true}\n",
        "Dari = \"data_inference_graph\" #@param [\"pre_trained_model\", \"data_inference_graph\"]\n",
        "\n",
        "\n",
        "label_map_pbtxt_fname = '/content/drive/MyDrive/prototype-pendeteksi-objek/'+Dari+'/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi+'/label_map.pbtxt'\n",
        "DEST_DIR = '/content/drive/MyDrive/prototype-pendeteksi-objek/'+Dari+'/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi\n",
        "\n",
        "\n",
        "#model_dir='/content/drive/MyDrive/pendeteksi-objek/data_training/tensorflow_v'+ Versi_Tensorflow +'/'+ Pendeteksi\n",
        "# NOTE: Pieces taken from https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "# The github.com/tensorflow/models is distributed under the Apache 2.0 license.\n",
        "\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import base64 \n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "# setup path so that model can be found.\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/prototype-pendeteksi-objek/models/research/object_detection')\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils\n",
        "\n",
        "# Taken from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=SucxddsPhOmj\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy\n",
        "import PIL.Image\n",
        "\n",
        "checkpoint_name = DEST_DIR\n",
        "#checkpoint = '{0}.ckpt'.format(checkpoint_name)\n",
        "\n",
        "with tf.get_default_graph().as_default() as graph:  \n",
        "\n",
        "  # This section builds a \"graph\" in TensorFlow to explain how to process the data.\n",
        "  jpeg_input_tensor = tf.placeholder(tf.string, ())  # We will provide a JPEG to TF.\n",
        "\n",
        "  # First, instruct TF to decode the JPEG string into a matrix.\n",
        "  image = tf.image.decode_image(jpeg_input_tensor)\n",
        "  image_tensor = tf.expand_dims(image, 0)\n",
        "\n",
        "  # Load the  graph from disk.\n",
        "  ssd_graph = tf.GraphDef()\n",
        "  with open('{}/frozen_inference_graph.pb'.format(checkpoint_name), 'rb') as f:\n",
        "    ssd_graph.ParseFromString(f.read())\n",
        "    \n",
        "  # Tell TensorFlow we would like to inspect these parts of the network.\n",
        "  output_names = ['num_detections:0', \n",
        "                  'detection_boxes:0', \n",
        "                  'detection_scores:0',\n",
        "                  'detection_classes:0']\n",
        "  ops = dict(zip(output_names, tf.graph_util.import_graph_def(\n",
        "      ssd_graph, \n",
        "      input_map={'image_tensor': image_tensor},\n",
        "      return_elements=output_names)))\n",
        "    \n",
        "  # Also extract the decoded image from the network to draw bounding boxes.\n",
        "  ops['image'] = image\n",
        "\n",
        "\n",
        "\n",
        "def run_detection(sess, img):\n",
        "  \"\"\"Run one detection round.\"\"\"\n",
        "  output_dict = sess.run(ops, feed_dict={jpeg_input_tensor: img})\n",
        "\n",
        "  # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "  output_dict['num_detections'] = int(output_dict['num_detections:0'][0])\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes:0'][0].astype(numpy.int64)\n",
        "  output_dict['detection_boxes'] = output_dict['detection_boxes:0'][0]\n",
        "  output_dict['detection_scores'] = output_dict['detection_scores:0'][0]\n",
        "  \n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_pbtxt_fname,\n",
        "    use_display_name=True)\n",
        "    \n",
        "with tf.Session() as sess:\n",
        "  start_input()\n",
        "\n",
        "  label_html = 'Detectioning'\n",
        "  img_data = ''\n",
        "  while True:\n",
        "    capture_start = time.time()\n",
        "    js_reply = take_photo(label_html, img_data)\n",
        "    capture_end = time.time()\n",
        "    if not js_reply:\n",
        "      break\n",
        "\n",
        "    # Javascript returns a data URL, like:\n",
        "    #     data: image/jpeg;base64,<base-64 encoded data>\n",
        "    # To use the image, decode the base-64 encoded part and treat it as a JPEG.\n",
        "    jpeg_input = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    result = run_detection(sess, jpeg_input)\n",
        "    detect_end = time.time()\n",
        "    \n",
        "    # To reduce transfer sizes, we send just the bounding boxes drawn on a \n",
        "    # transparent PNG. Here, we create a blank PNG.\n",
        "    rgb_shape = result['image'].shape\n",
        "    rgba_shape = list(rgb_shape)[0:2] + [4]\n",
        "    image_np = numpy.zeros(rgba_shape, dtype=numpy.uint8)\n",
        "    \n",
        "    # Draw the bounding boxes in the RGB channels.\n",
        "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np[:, :, 0:3],  # sub-select RGB channels only; alpha is done below.\n",
        "      result['detection_boxes'],\n",
        "      result['detection_classes'],\n",
        "      result['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=result.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=3)\n",
        "    \n",
        "    # To be visible, the alpha channel also needs to be edited. Set the alpha\n",
        "    # channel to 255 (fully opaque) wherever anything was drawn.\n",
        "    image_t = image_np.transpose()\n",
        "    max_color = numpy.maximum(numpy.maximum(image_t[0], image_t[1]), image_t[2])\n",
        "    image_t[3] = numpy.clip(max_color, 0, 1) * 255\n",
        "    viz_end = time.time()\n",
        "\n",
        "    # Save the image as a PNG in memory and assemble a data URL.\n",
        "    im = PIL.Image.fromarray(image_np, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    im.save(iobuf, format='png')\n",
        "    img_data = 'data:image/png;base64,{}'.format(\n",
        "      (str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "    perf_measures = {\n",
        "        'server': (\n",
        "            ('take_photo', capture_end - capture_start),\n",
        "            ('run_detection', detect_end - capture_end),\n",
        "            ('visualize', viz_end - detect_end)\n",
        "        ),\n",
        "        'js': (\n",
        "            ('create', js_reply['create']),\n",
        "            ('show', js_reply['show']),\n",
        "            ('capture', js_reply['capture']),\n",
        "        ),\n",
        "    }\n",
        "    \n",
        "    label_text = 'img size: {}b\\ntime:\\n  server: {}\\n  js: {}'.format(\n",
        "        len(js_reply['img']),\n",
        "        ', '.join('{}: {:2.3f}s'.format(*x) for x in perf_measures['server']),\n",
        "        ', '.join('{}: {:2.3f}s'.format(x[0], x[1] / 1000) for x in perf_measures['js']),\n",
        "    )\n",
        "    \n",
        "    label_html = html.escape(label_text).replace('\\n', '<br/>')\n",
        "\n",
        "print('Finished')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XF-Z5NIm92i"
      },
      "source": [
        "\n",
        "\n",
        "#**Sumber Referensi**\n",
        "\n",
        "```\n",
        "Mart\\’\\in~Abadi, Ashish~Agarwal, Paul~Barham, Eugene~Brevdo, Zhifeng~Chen, Craig~Citro, … Xiaoqiang~Zheng. (2015). {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems.\n",
        "\n",
        "Skalski, P. (2019). Make Sense.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlzpumisPkxc"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('prototype-pendeteksi-objek.ipynb')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}